{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of AfterWork Data Science: Hyperparameter Tuning with Python","provenance":[{"file_id":"1WWBtyxcYedDTG9bCq54X2_7aUZebPmTA","timestamp":1623921424646}],"collapsed_sections":["I4acj-OTOP82","2jTFOxfaOd14","0CrlFuI-VjsD","QaKj_EYnVnJa","m4f-HCCzcsFn","S6xAx-PccsFq","mIk0U5Aqfhbz","X-RiKkKFOrVb","A9y1H556gVW_","W6ndQUsSizcy","okCcLzc11Pdg","1yNS9_mH1Pdk","k4U0vmDV1PfP"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VxYyRzuYN6u7"},"source":["<font color=\"blue\">To use this notebook on Google Colaboratory, you will need to make a copy of it. Go to **File** > **Save a Copy in Drive**. You can then use the new copy that will appear in the new tab.</font>"]},{"cell_type":"markdown","metadata":{"id":"6ABs5Pr5OOdM"},"source":["# AfterWork Data Science: Hyperparameter Tuning with Python"]},{"cell_type":"markdown","metadata":{"id":"I4acj-OTOP82"},"source":["### Pre-requisites"]},{"cell_type":"code","metadata":{"id":"rpvueFt9N2Wr","executionInfo":{"status":"ok","timestamp":1623921577777,"user_tz":-180,"elapsed":44,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}}},"source":["# We will start by running this cell which will import the necessary libraries\n","# ---\n","# \n","import pandas as pd                # Pandas for data manipulation\n","import numpy as np                 # Numpy for scientific computations"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2jTFOxfaOd14"},"source":["## 1. Manual Search"]},{"cell_type":"markdown","metadata":{"id":"0CrlFuI-VjsD"},"source":["### Example "]},{"cell_type":"code","metadata":{"id":"UQtTRKfhiMyR","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1623922396480,"user_tz":-180,"elapsed":1677,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}},"outputId":"f0263a6c-9a2e-4a7e-9b99-f49fa5c55c2f"},"source":["# Example \n","# ---\n","# Question: Will John, 40 years old with a salary of 2500 will buy a car?\n","# ---\n","# Dataset url = http://bit.ly/SocialNetworkAdsDataset\n","# ---\n","#\n","social_df = pd.read_csv('http://bit.ly/SocialNetworkAdsDataset') \n","\n","social_df"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User ID</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>EstimatedSalary</th>\n","      <th>Purchased</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15624510</td>\n","      <td>Male</td>\n","      <td>19</td>\n","      <td>19000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>15810944</td>\n","      <td>Male</td>\n","      <td>35</td>\n","      <td>20000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>15668575</td>\n","      <td>Female</td>\n","      <td>26</td>\n","      <td>43000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>15603246</td>\n","      <td>Female</td>\n","      <td>27</td>\n","      <td>57000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>15804002</td>\n","      <td>Male</td>\n","      <td>19</td>\n","      <td>76000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>395</th>\n","      <td>15691863</td>\n","      <td>Female</td>\n","      <td>46</td>\n","      <td>41000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>396</th>\n","      <td>15706071</td>\n","      <td>Male</td>\n","      <td>51</td>\n","      <td>23000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>397</th>\n","      <td>15654296</td>\n","      <td>Female</td>\n","      <td>50</td>\n","      <td>20000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>398</th>\n","      <td>15755018</td>\n","      <td>Male</td>\n","      <td>36</td>\n","      <td>33000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>399</th>\n","      <td>15594041</td>\n","      <td>Female</td>\n","      <td>49</td>\n","      <td>36000</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>400 rows × 5 columns</p>\n","</div>"],"text/plain":["      User ID  Gender  Age  EstimatedSalary  Purchased\n","0    15624510    Male   19            19000          0\n","1    15810944    Male   35            20000          0\n","2    15668575  Female   26            43000          0\n","3    15603246  Female   27            57000          0\n","4    15804002    Male   19            76000          0\n","..        ...     ...  ...              ...        ...\n","395  15691863  Female   46            41000          1\n","396  15706071    Male   51            23000          1\n","397  15654296  Female   50            20000          1\n","398  15755018    Male   36            33000          0\n","399  15594041  Female   49            36000          1\n","\n","[400 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"Rr4jsDQ7UgDk","executionInfo":{"status":"ok","timestamp":1623922175868,"user_tz":-180,"elapsed":2133,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}}},"source":["# Step 1\n","# ---\n","# Loading our dataset \n","social_df = pd.read_csv('http://bit.ly/SocialNetworkAdsDataset') \n","\n","# Data preparation: Encoding\n","social_df[\"Gender\"] = np.where(social_df[\"Gender\"].str.contains(\"Male\", \"Female\"), 1, 0) \n","\n","# Defining our predictor and label variable\n","X = social_df.iloc[:, [1, 2 ,3]].values  # Independent/predictor variables\n","y = social_df.iloc[:, 4].values          # Dependent/label variable\n","\n","# Splitting our dataset\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)\n","\n","\n","# Performing scaling\n","from sklearn.preprocessing import StandardScaler\n","sc_X = StandardScaler() \n","X_train = sc_X.fit_transform(X_train)\n","X_test = sc_X.transform(X_test)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"jAjFNtLnOgJI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623922179011,"user_tz":-180,"elapsed":63,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}},"outputId":"84411e0d-a536-4eab-809d-1d361dfd8873"},"source":["# Step 2\n","# ---\n","# Defining our classifier\n","from sklearn.tree import DecisionTreeClassifier  \n","\n","# We will get to see the values of the Decision Tree classifier hyper parameters in the output below \n","# The decision tree has a quite a number of hyperparameters that require fine-tuning in order \n","# to get the best possible model that reduces the generalization error. \n","# To explore other decision tree hyperparameters, we can explore the sckit-learn documentation \n","# by following this link: https://bit.ly/3eu3XIh\n","# ---\n","# We will focus on two specific hyperparameters:\n","# 1. Max depth: This is the maximum number of children nodes that can grow out from \n","# the decision tree until the tree is cut off. \n","# For example, if this is set to 3, then the tree will use three children nodes \n","# and cut the tree off before it can grow any more. \n","# 2. Min samples leaf: This is the minimum number of samples, or data points, \n","# that are required to be present in the leaf node.\n","# ---\n","#\n","\n","from sklearn.tree import DecisionTreeClassifier  \n","decision_classifier = DecisionTreeClassifier(random_state=42)\n","\n","# Fitting our data\n","decision_classifier.fit(X_train, y_train)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n","                       max_depth=None, max_features=None, max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, presort='deprecated',\n","                       random_state=42, splitter='best')"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"jSqqtM59QxMw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623922254669,"user_tz":-180,"elapsed":497,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}},"outputId":"d787cfae-a72f-495f-bee4-97852faf6fec"},"source":["# Step 3\n","# ---\n","# Making our predictions\n","decision_y_prediction = decision_classifier.predict(X_test) \n","\n","# Calculating our metrics\n","# ---\n","#\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n","print(accuracy_score(decision_y_prediction, y_test))\n","print(confusion_matrix(decision_y_prediction, y_test))\n","print(classification_report(decision_y_prediction, y_test))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["0.84\n","[[56  9]\n"," [ 7 28]]\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.86      0.88        65\n","           1       0.76      0.80      0.78        35\n","\n","    accuracy                           0.84       100\n","   macro avg       0.82      0.83      0.83       100\n","weighted avg       0.84      0.84      0.84       100\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KE20z-jvT69F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623922267990,"user_tz":-180,"elapsed":727,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}},"outputId":"b8f0e84e-ff13-469a-8106-217591820519"},"source":["# Repeating Step 2\n","# ---\n","# Let's now perform hyper parameter tuning by setting \n","# the hyperparameters max_depth = 2 and min_samples_leaf = 100\n","# and get our output?\n","# ---\n","# \n","decision_classifier = DecisionTreeClassifier(max_depth = 2, min_samples_leaf = 50, random_state=42)\n","\n","# Fitting our data\n","decision_classifier.fit(X_train, y_train)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n","                       max_depth=2, max_features=None, max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=50, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, presort='deprecated',\n","                       random_state=42, splitter='best')"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"rygoolwDUzJk"},"source":["# Repeating Step 3\n","# --- \n","# Step 3\n","# ---\n","# Making our predictions\n","decision_y_prediction = decision_classifier.predict(X_test) \n"," \n","# Calculating our metrics \n","print(accuracy_score(decision_y_prediction, y_test))\n","print(confusion_matrix(decision_y_prediction, y_test))\n","print(classification_report(decision_y_prediction, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7KQIlwybVZtn"},"source":["Can you get a better accuracy? By tuning the same hyperparameters or other parameters?"]},{"cell_type":"markdown","metadata":{"id":"WJD2CgDZXVNj"},"source":["To read more about hyper parameter tuning for decision trees, you can refer to this reading: [Link](https://towardsdatascience.com/how-to-tune-a-decision-tree-f03721801680)"]},{"cell_type":"markdown","metadata":{"id":"QaKj_EYnVnJa"},"source":["### <font color=\"green\">Challenge</font>"]},{"cell_type":"code","metadata":{"id":"EsWOOvFmVvHc","executionInfo":{"status":"ok","timestamp":1623922445558,"user_tz":-180,"elapsed":1633,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}}},"source":["# Challenge 1\n","# ---\n","# Using the given dataset above, create a logistic regression classifier \n","# then tune its hyperparameters to get the best possible accuracy.\n","# Make a comparisons of your with other fellows in your breakout rooms.\n","# Hint: Use the following documentation to tune the hyper parameters.\n","# Sckit-learn documentation: https://bit.ly/2YZR4iP\n","# ---\n","# Dataset url = http://bit.ly/SocialNetworkAdsDataset\n","# \n","\n","\n","abc_df = pd.read_csv('http://bit.ly/SocialNetworkAdsDataset')\n","abc_df\n","\n","abc_df[\"Gender\"] = np.where(abc_df[\"Gender\"].str.contains(\"Male\", \"Female\"), 1, 0) \n","\n","# Defining our predictor and label variable\n","X = abc_df.iloc[:, [1, 2 ,3]].values  # Independent/predictor variables\n","y = abc_df.iloc[:, 4].values          # Dependent/label variable\n","\n","# Splitting our dataset\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)\n","\n","\n","# Performing scaling\n","from sklearn.preprocessing import StandardScaler\n","sc_X = StandardScaler() \n","X_train = sc_X.fit_transform(X_train)\n","X_test = sc_X.transform(X_test)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C8VQn6bPVqD3","executionInfo":{"status":"ok","timestamp":1623922748876,"user_tz":-180,"elapsed":820,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}},"outputId":"67a4f6f0-29dc-45bb-ff10-7296b660ca32"},"source":["\n","from sklearn.tree import DecisionTreeClassifier  \n","decision_classifier = DecisionTreeClassifier(random_state=42)\n","\n","# Fitting our data\n","decision_classifier.fit(X_train, y_train)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n","                       max_depth=None, max_features=None, max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, presort='deprecated',\n","                       random_state=42, splitter='best')"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BI7WtroGVugk","executionInfo":{"status":"ok","timestamp":1623922766500,"user_tz":-180,"elapsed":787,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}},"outputId":"74b98009-73b1-4b91-a283-eb553dbca117"},"source":["# Step 3\n","# ---\n","# Making our predictions\n","decision_y_prediction = decision_classifier.predict(X_test) \n","\n","# Calculating our metrics\n","# ---\n","#\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n","print(accuracy_score(decision_y_prediction, y_test))\n","print(confusion_matrix(decision_y_prediction, y_test))\n","print(classification_report(decision_y_prediction, y_test))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["0.84\n","[[56  9]\n"," [ 7 28]]\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.86      0.88        65\n","           1       0.76      0.80      0.78        35\n","\n","    accuracy                           0.84       100\n","   macro avg       0.82      0.83      0.83       100\n","weighted avg       0.84      0.84      0.84       100\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U7pJMp1qVy6Q","executionInfo":{"status":"ok","timestamp":1623922784457,"user_tz":-180,"elapsed":587,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}},"outputId":"089129e1-46d3-4844-e418-dd86e000304b"},"source":["\n","decision_classifier = DecisionTreeClassifier(max_depth = 2, min_samples_leaf = 50, random_state=42)\n","\n","# Fitting our data\n","decision_classifier.fit(X_train, y_train)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n","                       max_depth=2, max_features=None, max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=50, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, presort='deprecated',\n","                       random_state=42, splitter='best')"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ct_IM9aXV2QV","executionInfo":{"status":"ok","timestamp":1623922797997,"user_tz":-180,"elapsed":480,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}},"outputId":"429c95e2-3d18-42b4-db12-287eccc86aea"},"source":["# Repeating Step 3\n","# --- \n","# Step 3\n","# ---\n","# Making our predictions\n","decision_y_prediction = decision_classifier.predict(X_test) \n"," \n","# Calculating our metrics \n","print(accuracy_score(decision_y_prediction, y_test))\n","print(confusion_matrix(decision_y_prediction, y_test))\n","print(classification_report(decision_y_prediction, y_test))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["0.9\n","[[54  1]\n"," [ 9 36]]\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.98      0.92        55\n","           1       0.97      0.80      0.88        45\n","\n","    accuracy                           0.90       100\n","   macro avg       0.92      0.89      0.90       100\n","weighted avg       0.91      0.90      0.90       100\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m4f-HCCzcsFn"},"source":["## 2. Grid Search"]},{"cell_type":"markdown","metadata":{"id":"S6xAx-PccsFq"},"source":["### Example"]},{"cell_type":"code","metadata":{"id":"UJFIl1t9WrDw","executionInfo":{"status":"ok","timestamp":1623923021164,"user_tz":-180,"elapsed":752,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}}},"source":["# We will start by running this cell which will import the necessary libraries\n","# ---\n","# \n","import pandas as pd                # Pandas for data manipulation\n","import numpy as np                 # Numpy for scientific computations"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"VFnMcdWliR-E","executionInfo":{"status":"ok","timestamp":1623923214577,"user_tz":-180,"elapsed":456,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}}},"source":["# Example \n","# ---\n","# Question: Will John, 40 years old with a salary of 2500 will buy a car?\n","# ---\n","# Dataset url = http://bit.ly/SocialNetworkAdsDataset\n","# ---\n","#"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"jotViGxKb8Yp","executionInfo":{"status":"ok","timestamp":1623923217511,"user_tz":-180,"elapsed":96,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}}},"source":["# Step 2\n","# ---\n","# Defining our classifier \n","\n","# We will get to see the values of the Decision Tree classifier hyper parameters in the output below \n","# The decision tree has a quite a number of hyperparameters that require fine-tuning in order \n","# to get the best possible model that reduces the generalization error. \n","# To explore other decision tree hyperparameters, we can explore the sckit-learn documentation \n","# by following this link: https://bit.ly/3eu3XIh\n","# ---\n","# Again we will focus on the same two specific hyperparameters:\n","# 1. Max depth: This is the maximum number of children nodes that can grow out from \n","# the decision tree until the tree is cut off. \n","# For example, if this is set to 3, then the tree will use three children nodes \n","# and cut the tree off before it can grow any more. \n","# 2. Min samples leaf: This is the minimum number of samples, or data points, \n","# that are required to be present in the leaf node.\n","# ---\n","# \n","decision_classifier = DecisionTreeClassifier(random_state=42)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q03AxVzIZprI","executionInfo":{"status":"ok","timestamp":1623923226755,"user_tz":-180,"elapsed":15,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}}},"source":["# Step 3: Hyperparameters: Getting Started with Grid Search\n","# ---\n","# We will continue from where we left off from the previous example,\n","# We will create a dictionary of all the parameters and their corresponding \n","# set of values that you want to test for best performance. \n","# The name of the dictionary items corresponds to the parameter name \n","# and the value corresponds to the list of values for the parameter.\n","# As shown grid_param dictionary with two parameters max_depth, min_samples_leaf.\n","# The parameter values that we want to try out are passed in the list.   \n","# The Grid Search algorithm basically would check for all possible combinations \n","# of parameter values and returns the combination with the best accuracy. \n","# For instance, in the above case the Grid Search algorithm \n","# will check all combinations (5 x 5 = 25).\n","# ---\n","# \n","grid_param = {\n","    'max_depth': [2, 3, 4, 10, 15],\n","    'min_samples_leaf': [10, 20, 30, 40, 50]\n","}"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"FgzqZY71Z2Vv","executionInfo":{"status":"ok","timestamp":1623923229049,"user_tz":-180,"elapsed":12,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}}},"source":["# Step 2: Instantiating GridSearchCV object\n","# ---\n","# We then create an instance of the GridSearchCV class \n","# and pass values for the estimator parameter, \n","# which basically is the algorithm that you want to execute. \n","# The param_grid parameter takes the created grid dictionary \n","# The scoring parameter takes the performance metrics, \n","# the cv parameter corresponds to number of folds, which will set 5 in our case, \n","# and finally the n_jobs parameter refers to the number of CPU's that we want to use for execution. \n","# Setting the value of n_jobs = -1 allows us us to use all available computing power.\n","# You can refer to the GridSearchCV documentation to find out more: https://bit.ly/2Yr0qVC\n","# ---\n","# \n","from sklearn.model_selection import GridSearchCV\n","gd_sr_cl = GridSearchCV(estimator = decision_classifier,\n","                     param_grid = grid_param,\n","                     scoring = 'accuracy',\n","                     cv = 5,\n","                     n_jobs =-1)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"xurXa_ovZ5JE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623923231482,"user_tz":-180,"elapsed":1563,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}},"outputId":"b6a57ab9-3f95-47f2-cc55-e564d60f2a0b"},"source":["# Step 3: Calling the fit method\n","# ---\n","# We now fit our data and call the fit method of the class \n","# and pass it the training and test set, as shown in the following code.\n","# If we had lost of other parameters this would take abit of some time to execute. \n","# This is because the GridSearchCV would go through all the combinations of hyperparameters. \n","# ---\n","# \n","gd_sr_cl.fit(X_train, y_train)"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5, error_score=nan,\n","             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n","                                              criterion='gini', max_depth=None,\n","                                              max_features=None,\n","                                              max_leaf_nodes=None,\n","                                              min_impurity_decrease=0.0,\n","                                              min_impurity_split=None,\n","                                              min_samples_leaf=1,\n","                                              min_samples_split=2,\n","                                              min_weight_fraction_leaf=0.0,\n","                                              presort='deprecated',\n","                                              random_state=42,\n","                                              splitter='best'),\n","             iid='deprecated', n_jobs=-1,\n","             param_grid={'max_depth': [2, 3, 4, 10, 15],\n","                         'min_samples_leaf': [10, 20, 30, 40, 50]},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n","             scoring='accuracy', verbose=0)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"gSjIyP6iZ7gM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623923231500,"user_tz":-180,"elapsed":99,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}},"outputId":"88762f72-024d-4e0e-8475-09b026db4c98"},"source":["# Step 4\n","# --- \n","# We use gd_sr_cl.best_params_ attribute of the GridSearchCV object\n","# to check the parameters with the highest accuracy\n","# ---\n","# \n","best_parameters = gd_sr_cl.best_params_\n","print(best_parameters)\n"," \n","# We shouldn't stop here however, instead we should add  \n","# other estimators and see if the accuracy increases  "],"execution_count":23,"outputs":[{"output_type":"stream","text":["{'max_depth': 3, 'min_samples_leaf': 10}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DY8IpIK1Z9gs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623923233270,"user_tz":-180,"elapsed":22,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}},"outputId":"05ac8d76-e941-46ed-d0ad-bcc1b70fac1a"},"source":["# Step 5: Finding the obtained accuracy\n","# ---\n","# We can also obtain the best accuracy by doing the following\n","# ---\n","# \n","best_result = gd_sr_cl.best_score_\n","print(best_result)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["0.9066666666666666\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8NZOSpZBc7CU"},"source":["Can you get a better accuracy? By refering to the decision tree documentation, choosing additional approriate hyper-parameters and set the hyperparameter values to the grid search space in an effort to get a better accuracy."]},{"cell_type":"markdown","metadata":{"id":"mIk0U5Aqfhbz"},"source":["### <font color=\"green\">Challenge</font>"]},{"cell_type":"code","metadata":{"id":"MEMGtQlpfk8c"},"source":["# Challenge\n","# ---\n","# In this challenge, we still be required to use grid search while using \n","# the logistic regression classifier we created earlier to get the best possible accuracy. \n","# Hint: Use the following documentation to tune the hyperparameters.\n","# Sckit-learn documentation: https://bit.ly/2YZR4iP\n","# ---\n","# Dataset url = http://bit.ly/SocialNetworkAdsDataset\n","# "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X-RiKkKFOrVb"},"source":["## 3. Random Search"]},{"cell_type":"markdown","metadata":{"id":"A9y1H556gVW_"},"source":["### Example"]},{"cell_type":"code","metadata":{"id":"fPGxiGQFgVXB","executionInfo":{"status":"ok","timestamp":1623923288421,"user_tz":-180,"elapsed":736,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}}},"source":["# Example \n","# ---\n","# Question: Will John, 40 years old with a salary of 2500 will buy a car?\n","# ---\n","# Dataset url = http://bit.ly/SocialNetworkAdsDataset\n","# ---\n","#"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"pvOuYIxW8SaB","executionInfo":{"status":"ok","timestamp":1623923288424,"user_tz":-180,"elapsed":58,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}}},"source":["# Defining our classifier \n","# ---\n","# We will get to see the values of the Decision Tree classifier hyper parameters in the output below \n","# The decision tree has a quite a number of hyperparameters that require fine-tuning in order \n","# to get the best possible model that reduces the generalization error. \n","# To explore other decision tree hyperparameters, we can explore the sckit-learn documentation \n","# by following this link: https://bit.ly/3eu3XIh\n","# ---\n","# Again, we will focus on the same two specific hyperparameters:\n","# 1. Max depth: This is the maximum number of children nodes that can grow out from \n","# the decision tree until the tree is cut off. \n","# For example, if this is set to 3, then the tree will use three children nodes \n","# and cut the tree off before it can grow any more. \n","# 2. Min samples leaf: This is the minimum number of samples, or data points, \n","# that are required to be present in the leaf node.\n","# ---\n","# \n","decision_classifier = DecisionTreeClassifier(random_state=42)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"vUTlhWCWglW_","executionInfo":{"status":"ok","timestamp":1623923288426,"user_tz":-180,"elapsed":56,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}}},"source":["# Step 1: Hyperparameters: Getting Started with Random Search\n","# ---\n","# While performing random search, we would need to provide a statistical distribution \n","# for each hyperparameter from which values may be randomly sampled.\n","# We'll define a sampling distribution for each hyperparameter.\n","# ---\n","# \n","\n","# Let's define our parameters and the respective distributions to sample from\n","# ---\n","#\n","from scipy.stats import randint as sp_randint\n","param_dist = {\"max_depth\": [3, None], \n","              \"min_samples_leaf\": sp_randint(1, 50)}"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"lyDyEIalgmiN","executionInfo":{"status":"ok","timestamp":1623923288430,"user_tz":-180,"elapsed":57,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}}},"source":["# Step 2\n","# ---\n","# We then instantiate our RandomizedSearchCV object \n","# ---\n","# We can read more about the RandomizedSearchCV documentation\n","# by following this link: https://bit.ly/2V9Xhri\n","# ---\n","#\n","from sklearn.model_selection import RandomizedSearchCV \n","random_sr = RandomizedSearchCV(decision_classifier, param_dist, cv = 5) "],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"1mVVunKJgrMT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623923288433,"user_tz":-180,"elapsed":58,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}},"outputId":"1b28c3dc-2ca6-460d-9d7c-d42f1e9ce7b2"},"source":["# Step 3: Then fitting our data\n","# ---\n","#\n","random_sr.fit(X_train, y_train)"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomizedSearchCV(cv=5, error_score=nan,\n","                   estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n","                                                    class_weight=None,\n","                                                    criterion='gini',\n","                                                    max_depth=None,\n","                                                    max_features=None,\n","                                                    max_leaf_nodes=None,\n","                                                    min_impurity_decrease=0.0,\n","                                                    min_impurity_split=None,\n","                                                    min_samples_leaf=1,\n","                                                    min_samples_split=2,\n","                                                    min_weight_fraction_leaf=0.0,\n","                                                    presort='deprecated',\n","                                                    random_state=42,\n","                                                    splitter='best'),\n","                   iid='deprecated', n_iter=10, n_jobs=None,\n","                   param_distributions={'max_depth': [3, None],\n","                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f67491a2b10>},\n","                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n","                   return_train_score=False, scoring=None, verbose=0)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"D4v1u9vVguNP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623923314135,"user_tz":-180,"elapsed":594,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}},"outputId":"9194680b-ae6f-4f13-dca0-9381ff5da497"},"source":["# Step 4: Checking for the best parameters\n","# ---\n","#\n","best_parameters = random_sr.best_params_\n","print(best_parameters)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["{'max_depth': 3, 'min_samples_leaf': 15}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AzKzEqLxgvx9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623923319346,"user_tz":-180,"elapsed":705,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}},"outputId":"3d9a812b-5714-49b7-cc31-1eed72c7d472"},"source":["# And lastly obtaining our accuracy\n","# --\n","# \n","best_result = random_sr.best_score_\n","print(best_result)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["0.9066666666666666\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qx4Qs-8rjUQu"},"source":["Can you get a better accuracy? By refering to the decision tree documentation, choosing additional approriate hyper-parameters and set the hyperparameter values to the random search space in an effort to get a better accuracy."]},{"cell_type":"markdown","metadata":{"id":"W6ndQUsSizcy"},"source":["### <font color=\"green\">Challenge</font>"]},{"cell_type":"code","metadata":{"id":"taJUBjUJizc0"},"source":["# Challenge\n","# ---\n","# Again, we will also be required to use random search while using \n","# the logistic regression classifier we created earlier to get the best possible accuracy. \n","# Hint: Use the following documentation to tune the hyperparameters.\n","# Sckit-learn documentation: https://bit.ly/2YZR4iP\n","# ---\n","# Dataset url = http://bit.ly/SocialNetworkAdsDataset\n","# "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"okCcLzc11Pdg"},"source":["## 4. Bayesian Optimisation "]},{"cell_type":"markdown","metadata":{"id":"1yNS9_mH1Pdk"},"source":["### Example"]},{"cell_type":"code","metadata":{"id":"dQ6F9fmA1Pdq"},"source":["# Example \n","# ---\n","# Question: Will John, 40 years old with a salary of 2500 will buy a car?\n","# ---\n","# Dataset url = http://bit.ly/SocialNetworkAdsDataset\n","# ---\n","#"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3R72DljV7mWb"},"source":["# Defining our classifier \n","# ---\n","# We will get to see the values of the Decision Tree classifier hyper parameters in the output below \n","# The decision tree has a quite a number of hyperparameters that require fine-tuning in order \n","# to get the best possible model that reduces the generalization error. \n","# To explore other decision tree hyperparameters, we can explore the sckit-learn documentation \n","# by following this link: https://bit.ly/3eu3XIh\n","# ---\n","# Again, we will focus on the same two specific hyperparameters:\n","# 1. Max depth: This is the maximum number of children nodes that can grow out from \n","# the decision tree until the tree is cut off. \n","# For example, if this is set to 3, then the tree will use three children nodes \n","# and cut the tree off before it can grow any more. \n","# 2. Min samples leaf: This is the minimum number of samples, or data points, \n","# that are required to be present in the leaf node.\n","# ---\n","# "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"havuVOJ81Pd9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623923633681,"user_tz":-180,"elapsed":1779,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}},"outputId":"07615a97-81a4-4d18-dd69-ea3b14d0cedc"},"source":["# Step 1: Hyperparameters: Getting Started with Bayesian Optimisation\n","# ---\n","# While performing bayesian optimisation, we perform the following steps, \n","# 1. Set up a space dictionary.\n","# - In this space, we create a probability distribution for each of the used hyperparameters.\n","# 2. Set up the objective function using the respective classifier/regressor.\n","# 3. Run our Bayesian Optimizer.\n","# ---\n","# \n","\n","# Let's define set up our space dictionary \n","# ---\n","#\n","\n","# We will import the hyperopt library which will helps us perform bayesian optimisation\n","# ---\n","# Hyperopt librariy documentation: https://bit.ly/2Dyynf4\n","# ---\n","#\n","from hyperopt import hp, fmin, tpe, STATUS_OK\n","from sklearn.model_selection import cross_val_score\n","\n","# 1. Setting up a our space dictionary\n","# ---\n","#\n","space = {'max_depth': hp.quniform('max_depth', 10, 1200, 10), \n","        'min_samples_leaf': hp.uniform ('min_samples_leaf', 0, 0.5)}\n","\n","# 2. Setting up our objective function\n","# ----\n","#\n","def objective(space): \n","    classifier = DecisionTreeClassifier(max_depth = space['max_depth'],\n","                                 min_samples_leaf = space['min_samples_leaf'])\n","    \n","    accuracy = cross_val_score(classifier, X_train, y_train, cv = 4).mean() \n","\n","    # We aim to maximize accuracy, therefore we return it as a negative value\n","    return {'loss': -accuracy, 'status': STATUS_OK }\n","\n","# 3. Running our bayesian optimizer\n","# ---\n","#\n","best = fmin(fn= objective,                        # the objective function to miminize / the loss function to minimize\n","            space = space,                        # the range of input values to test during optimisation\n","            algo= tpe.suggest,                    # the search algorithm to use\n","            max_evals = 80,                       # the no. of iteration to perform\n","            rstate=np.random.RandomState(42))     # the randomstate for reproducability / to get the same result when we run the code\n","\n","# printing out our outcome\n","best"],"execution_count":35,"outputs":[{"output_type":"stream","text":["100%|██████████| 80/80 [00:00<00:00, 89.48it/s, best loss: -0.9066666666666666]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'max_depth': 630.0, 'min_samples_leaf': 0.08629075344668666}"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"opu_jYhf_0Wn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623923646107,"user_tz":-180,"elapsed":457,"user":{"displayName":"Kuria K. Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnEdqxk2Mp_jIE4QawUovTRuGsreOMU5LcwWtLIw=s64","userId":"18249265223060828810"}},"outputId":"4d03d259-b0ca-4729-9365-822a467986d8"},"source":["# We can access values of the above paramemters by\n","# ---\n","#\n","print(\"Max Depth:\", best['max_depth'])\n","print(\"Min Samples Leaf:\", best['min_samples_leaf'])"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Max Depth: 630.0\n","Min Samples Leaf: 0.08629075344668666\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6jJPl9FH5YiO"},"source":["# Let's now perform our classification with our optimal hyperparameters  \n","# ---\n","# \n","decision_classifier = DecisionTreeClassifier(max_depth = best['max_depth'], \n","                                             min_samples_leaf = best['min_samples_leaf'], random_state=42)\n","\n","# Fitting our data\n","decision_classifier.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XSHEGoUL6I_R"},"source":["# Making our predictions\n","# ---\n","#\n","decision_y_prediction = decision_classifier.predict(X_test) \n","\n","# Calculating our metrics \n","print(accuracy_score(decision_y_prediction, y_test))\n","print(confusion_matrix(decision_y_prediction, y_test))\n","print(classification_report(decision_y_prediction, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BPAUxzjx1PfO"},"source":["Can you get a better accuracy? By refering to the decision tree documentation, choosing additional approriate hyper-parameters and set the hyperparameter values to the  search space in an effort to get a better accuracy."]},{"cell_type":"markdown","metadata":{"id":"k4U0vmDV1PfP"},"source":["### <font color=\"green\">Challenge</font>"]},{"cell_type":"code","metadata":{"id":"_Q5dXaLj1PfP"},"source":["# Challenge\n","# ---\n","# Again, we will also be required to use bayesian optimisation while using \n","# the logistic regression classifier we created earlier to get the best possible accuracy. \n","# Hint: Use the following documentation to tune the hyperparameters.\n","# Sckit-learn documentation: https://bit.ly/2YZR4iP\n","# ---\n","# Dataset url = http://bit.ly/SocialNetworkAdsDataset\n","# "],"execution_count":null,"outputs":[]}]}